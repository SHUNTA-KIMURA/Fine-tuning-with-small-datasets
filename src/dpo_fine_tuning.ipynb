{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Jm2C4XWEnVRy"
   },
   "outputs": [],
   "source": [
    "!pip install --upgrade pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "blIQ38ismwNf"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "from huggingface_hub import login\n",
    "login()\n",
    "\n",
    "# Change by user\n",
    "USER = \"user0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "i_LpHwtrkuPS"
   },
   "outputs": [],
   "source": [
    "!pip install -U transformers datasets peft trl accelerate bitsandbytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "u7gUOQ-05S5U"
   },
   "outputs": [],
   "source": [
    "import bitsandbytes as bnb, torch\n",
    "print(\"cuda:\", torch.cuda.is_available())\n",
    "print(\"gpu:\", torch.cuda.get_device_name(0))\n",
    "print(\"bnb:\", bnb.__version__)\n",
    "print(torch.__version__, torch.version.cuda)\n",
    "print(\"cuda:\", torch.cuda.is_available(), torch.cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CCz7uQJLsYwj"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import random\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "INPUT_DIR = Path(\"datasets\")\n",
    "OUTPUT_DIR = Path(\"datasets\")\n",
    "\n",
    "TRAIN_N = 20\n",
    "EVAL_N = 5\n",
    "SEED = 42\n",
    "\n",
    "random.seed(SEED)\n",
    "\n",
    "def split_user_file(path: Path):\n",
    "    rows = json.load(open(path, \"r\", encoding=\"utf-8\"))\n",
    "    assert len(rows) >= TRAIN_N + EVAL_N, f\"{path.name} has too few rows\"\n",
    "\n",
    "    rows = rows.copy()\n",
    "    random.shuffle(rows)\n",
    "\n",
    "    train = rows[:TRAIN_N]\n",
    "    eval_ = rows[TRAIN_N:TRAIN_N + EVAL_N]\n",
    "\n",
    "    user = path.stem\n",
    "\n",
    "    train_path = OUTPUT_DIR / f\"{user}_train.json\"\n",
    "    eval_path  = OUTPUT_DIR / f\"{user}_eval.json\"\n",
    "\n",
    "    json.dump(train, open(train_path, \"w\", encoding=\"utf-8\"), ensure_ascii=False, indent=2)\n",
    "    json.dump(eval_,  open(eval_path,  \"w\", encoding=\"utf-8\"), ensure_ascii=False, indent=2)\n",
    "\n",
    "    print(f\"{user}: train={len(train)}, eval={len(eval_)}\")\n",
    "\n",
    "\n",
    "for path in INPUT_DIR.glob(\"user*.json\"):\n",
    "    split_user_file(path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wVGVdtPpmCOQ",
    "outputId": "dfe9d8d7-7b00-4867-eee2-d06fbf019388"
   },
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "import json\n",
    "\n",
    "PATH = \"/content/drive/MyDrive/datasets\"\n",
    "\n",
    "def load_dataset(path: str) -> Dataset:\n",
    "    rows = json.load(open(path, \"r\", encoding=\"utf-8\"))\n",
    "    converted = []\n",
    "    for r in rows:\n",
    "        converted.append({\n",
    "            \"prompt\": r[\"query\"],\n",
    "            \"chosen\": r[\"chosen\"],\n",
    "            \"rejected\": r[\"reject\"],\n",
    "        })\n",
    "    return Dataset.from_list(converted)\n",
    "\n",
    "train_dataset = load_dataset(f\"{PATH}/{USER}_train.json\")\n",
    "eval_dataset  = load_dataset(f\"{PATH}/{USER}_eval.json\")\n",
    "\n",
    "print(train_dataset[0])\n",
    "print(train_dataset.column_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "T15Rtw1pymsc",
    "outputId": "ed394bc0-60ae-43f1-e81b-d88387034032"
   },
   "outputs": [],
   "source": [
    "import bitsandbytes as bnb\n",
    "import bitsandbytes\n",
    "print(\"bnb:\", bnb.__version__)\n",
    "print(\"bnb path:\", bitsandbytes.__file__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9ZDxTlatqSNz"
   },
   "source": [
    "When this quantification doesn't work, try \"retry runtime.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 504,
     "referenced_widgets": [
      "fac534890d9642ee916f63097b4dd6ab",
      "26a23c0286774e1c8a94bdcc45cff512",
      "dd984d14b4bc4a6ca9ac23be6254de62",
      "a8cadfc8501545b79e8366c5e0bc14b7",
      "3528fcf32cb54ec4bcb7a4fbba812dbf",
      "30b3578b6232490bad0a64318c1368f5",
      "6f028a88867c462c8357b4c9af474dfc",
      "f5f8895cd8284140b7dacd78dd86c548",
      "24b94a54a57b46d08089ab9976859722",
      "bd96e1b8562546a68010c85f26fc1f30",
      "badd510966b84c2f9810669981cd24e8",
      "70799925288e4c5c9c53346b86af286d",
      "10a1815aa0634817bd2922747a833a08",
      "793af44f93c44435b8e61a6f774d6357",
      "5460659e6c1945e69c0f8af95e2e87bd",
      "fe29967a36d84f178a01ee171c704b57",
      "396b389e04a849babe15d3cb56de71e8",
      "0973d76088834cb585088275aa7ea020",
      "753110238c754bf68c91fae84a9e33bf",
      "9cf9b0e23bab4202a6042db9672def4d",
      "43a0126901844c9983b98e40bd376c91",
      "a196b3d9cf2d46569e066731ce2dd12f",
      "c611e264d3d24e9383bf4b33ee969472",
      "202c2070f9094a60837513c14bc75c03",
      "370a840c3a57439cba7b2fdabe65f3c6",
      "5baf29b8618449aa992255770f6cbbe8",
      "d4f6adc1047648f4b236830f6e732ca6",
      "692d96fabd8e4b79baccb4de7568d3dd",
      "72523f099c4a4ba9a35dcb89011ce239",
      "f7a21e81b29a457d9558140d30568150",
      "0f511e982113427aaaee4b060cc717f9",
      "bff89af9b6dc43b8b0c78ee64101d79b",
      "11b148c53b834f0e962bcee3e0d68475",
      "59f55c2abb974e61b14250fe3498da5d",
      "2b7e92326a724f2a9537076af135fddb",
      "32748c0890b649d392ebfb5b998c869b",
      "979bf8e53937401dbe2273e2105b1f31",
      "ad941c12d68b49a5af8f6557d2623540",
      "d2c09f5569bf405b9944eaa81f0aabb1",
      "70fb87b4b74e450ea3070971b86ac6a3",
      "3f88e8dd0c234d669984beb4e5a0e719",
      "6a98c6e003ee42418211d1fa23f34e40",
      "b2a14a958a6949ee889095546e2fd98b",
      "07e35dbb69534dd6bbf097b83532e579",
      "ec276d4aeae24f2483858fadc88ba97b",
      "c8c3bda2e9a3418fb3faa3cd6e151b27",
      "496889584f9842c687c535fd9003991c",
      "077ec40fc071458a89a6da72667ce7f7",
      "b0c0df4bb9714bdc9fe1ce7fff8d9832",
      "b955b16f3ed847b38e6a2577fccdfd73",
      "ad51049367654ceab9d93d7b448167c3",
      "6d68f2fea4624a5898dfb3abf3764905",
      "3e2d927f1fcd4bffbba76093b5dfe7bd",
      "ea096656867748deafbce8791e0a1dbf",
      "ee52d91b4be04206acda275b516b5134",
      "ce68203f2d574e44869127fe828083f6",
      "55abbf5729dc4233bab2a2c07702e9a1",
      "74ec6a29697648c0a0af2902f0aaee47",
      "619f47c191bb457ba8f6ad7a96f3ac59",
      "89a8f77960f444d8bb6dd88d5f934e26",
      "66b882a9a4a24d4296e25df1821d59ca",
      "a07d5f18226844db80f442eec36b4105",
      "50d733ad46a7472db5c4a0c5fb5d6fac",
      "baeb2bcbd9de4f0db4b502c0cf4e3640",
      "499c3a926c2e4945b9d54df3565c5d4d",
      "f87e45efc2e644a483841cb692756270",
      "5aaaffe60c7f4e279e4bfbdfa6dc84c0",
      "b61e34450a5c483295098c15d49b6b3f",
      "5bdec454efdb4eb7904a010d664ff427",
      "02c5a5eede0645bb84c148f682b6e573",
      "63fe23d5cd6849a4b5f7b87d60824cf7",
      "b90321edd1b94bd99a0fac0ac14f58bc",
      "a20e835db7f047bb9044cc94a81d09af",
      "d6ebe4496dc14c1bb1964c7458f1de87",
      "11a24c4283a8403f8286bfc982ea7948",
      "4c0ae6f1419a4d77856165a3c17dc5a3",
      "6c6be075cc7843d5bd5481ba04f3a0f9",
      "d555451562144c6c821b6d253f1225b5",
      "eda16dfc28cc46698c55d96c8a518600",
      "f3bc52b3d90f40d392090689c0c19856",
      "cfbd297810274b0a8a88dca5a37c398c",
      "e441ad00834846ea8d1cf42dff42a859",
      "149df60b12b540e285f3b6911b8542f9",
      "fee69077360b43a68fdcb40d434e4375",
      "449c6ca7a8a34442a61dfb3e6ec208de",
      "083a4e92bd99424fbc0facce7b5b0c8f",
      "350f310d1e92410ba03503b638de32b2",
      "ba291c12c5824e1bb700ce92d7cdfca9",
      "8e52e208599f462b8814b8e9a990d835",
      "9113f17de7174bc88fd0871c98f2d300",
      "1bdfc772b7f349a984e1ce7d0087c2e7",
      "a9de498d1a6d460780028b75c0b192b9",
      "df640c8b6f7640a8b7a12a79248e0db4",
      "33cd784a386c4eb3b66b360313014271",
      "824d53a8771846a5adf5d0fc992045d7",
      "1526bf812c374e7e992098d7f59c1840",
      "e1a9b41040c248d1b3999f178257023b",
      "a9448e4e2fb240dca2fd5bef39f09e9b",
      "ac24ed89a51341adb359225553675535",
      "cabed6d588e644238edd539afb4dd613",
      "52b009fc41154ec0b9b8868d9795b115",
      "b768b7bd7af649fba0b8fc0c7539ecde",
      "a67112f71bc24321ba82f5fb323f33f4",
      "9f4bd5dfd96d48b2afa03c21273fb29d",
      "38bb58c4af3541cca121bf1646676a26",
      "23b6c52e80d947e0ad9f0e67ac3c830d",
      "2f99ee5ce0264bdcb56fa9243d464eaa",
      "b617ae79ccda43a88601ff6b0fcde5ce",
      "7110447b1eac4fa2a65c05c1c8af42c0",
      "4d6a48ab1a7443e69283bb4ddd8d7b04"
     ]
    },
    "id": "IiUTsoHpmNIl",
    "outputId": "df3dc1c0-6643-40f8-ef4f-0d2cb0673458"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
    "from peft import LoraConfig, get_peft_model, prepare_model_for_kbit_training\n",
    "\n",
    "MODEL_ID = \"meta-llama/Llama-3.2-3B-Instruct\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_ID, use_fast=True)\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16,\n",
    ")\n",
    "\n",
    "\n",
    "base_model = AutoModelForCausalLM.from_pretrained(\n",
    "    MODEL_ID,\n",
    "    device_map={\"\": 0},\n",
    "    quantization_config=bnb_config,\n",
    "    torch_dtype=torch.bfloat16,\n",
    ")\n",
    "\n",
    "# LoRA + 4bit\n",
    "base_model = prepare_model_for_kbit_training(base_model)\n",
    "\n",
    "lora_cfg = LoraConfig(\n",
    "    r=16,\n",
    "    lora_alpha=32,\n",
    "    lora_dropout=0.05,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\",\n",
    "    target_modules=[\"q_proj\",\"k_proj\",\"v_proj\",\"o_proj\"],\n",
    ")\n",
    "\n",
    "model = get_peft_model(base_model, lora_cfg)\n",
    "model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 49,
     "referenced_widgets": [
      "4eef42591f604726ac7a2706ce7021bb",
      "8aca4bb7bee24ea2870144c768cdc810",
      "fcc6191094734230a53e2d2a30e668e1",
      "495195d628804e7989ba2e937fd110b3",
      "055643612b1f4ac5b8b50cc4bb336ee7",
      "022ae5ff89fa4001aba9b8148a0bc17b",
      "71968dd50f754fbe8025a5743dc2c162",
      "b30349b3b8924b21b2c40456532de11b",
      "1516ac378d8a4090b95a1b6f64b44d63",
      "50558d724650456895be10f114159616",
      "e17965cc2b6649a7ac2114f5fa0c76ea"
     ]
    },
    "id": "VoU-1QmYmero",
    "outputId": "9f0d7df3-d3b8-498e-9456-89bd57f0f218"
   },
   "outputs": [],
   "source": [
    "ref_model = AutoModelForCausalLM.from_pretrained(\n",
    "    MODEL_ID,\n",
    "    device_map={\"\": \"cpu\"},\n",
    "    torch_dtype=torch.bfloat16,\n",
    ")\n",
    "ref_model.eval()\n",
    "ref_model.config.use_cache = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1Q0gYkw62JEu"
   },
   "outputs": [],
   "source": [
    "model = model.to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 306,
     "referenced_widgets": [
      "17a878c925f34c2fbb2cbb9d1ccbccd5",
      "264050eca3ed40678522b7da7c5a4b1a",
      "5ff7a1f38d524aa89c38379037c43cb8",
      "0733fb16ae4c499fa546859e99ee5572",
      "bbd95d96eb504f98a34f1b95c58b2323",
      "6221530133de45d5aeabdb4b47e6a5f9",
      "e2ca8ecfdaf742b78d932ee8c1ce5bdf",
      "5b8d1abb384b4fc29a1d05d6e6fcb608",
      "7fd370127d334453804cb6ff34af9e5a",
      "a136c62b1f654c05adc39198f37c8e40",
      "2b5b4183a9d148aa87e44732e89026a4",
      "9b70979e82f7469ebd55c1465b5d9969",
      "a24691d41e934c1db770309c3fc13f4c",
      "13e84a1d973448e8a23d484c3cccda0a",
      "1807ba4dfeaa4bd583644ae796dbf318",
      "790379862cfa49e3976c4659da8e7e76",
      "a526aacb01d242df9863d1a1dd91b29e",
      "8692063d79e1484eb8d050a43571efae",
      "d1fae462da7144c1ab3b00414c9de410",
      "e84c9d9e6d634bc28976fe3fff0bb9ba",
      "3277e10ea6db4e2bb4c4ccecc674153c",
      "23cf55be8e01471cb2c1b2767e6b892d",
      "9c5e13a406d7412389efed8b9ec82094",
      "8fe223b8e5f24ac289e9ce0dc35640b6",
      "45059d72a1b74c61b4c840c0841719fb",
      "0c232414d3ae4770a026cd858179833a",
      "fd611ec8435840a78441630c034e1d73",
      "bfb5a1694eae49e4b55dc92e31715762",
      "0dccd8aaf3b445eeb526b9ae60484f81",
      "892a427f5b204f77a007a2ce2901f75d",
      "29d5592880d44faeb8431963fa877cf1",
      "f9ac5499d2c2408ea194be37a36a2b45",
      "ab7a3236ccac4325bd946ed92141035a",
      "cdcfb5d05b6a42f4aa3593ec9b000ea7",
      "0386cfc6ad284e27b4afbf2189ae3a56",
      "b85c0bfb9c8c44aa9be73eba4f58a7f2",
      "7c960c0f6fa7435e9103078adb700808",
      "2112ee89349d48599907da07e661cdf3",
      "0084aee193244c1ebdd5913d8d9f2e72",
      "1f0f07710c874cf0b92b702bd59a2f50",
      "2f7e715c81d848eb9558f406f91ffbcf",
      "ea1f8d3db8b0400f99b183a7ee0d79e6",
      "0e90eb533fd44ee390e6556a3238b52c",
      "373ac9e513a74829a7084ef53ba7fb4a",
      "55e667e041104f5d9b3f7c84ec0587f0",
      "9480df137bf645fdb9504a1ca2ddc833",
      "0635c7e4fb5445e9a4438a61d63b711e",
      "2846ee640c7c4ab38cb56e906fb1637e",
      "d278fb610af8465ba961dc5f8ddbd711",
      "3c61cafd5b5345cc9ee527be59857b1c",
      "2e2e5f93f24d4b22af2c75eff41f8ab7",
      "04df85ead1ff4a0f9eac9755dac62719",
      "401135cfb4444edeb6ceebee1fe2b4de",
      "78787cf4c5b74a9380738550b4490ca0",
      "19d2f0a102b2431d9a69a287480244c3",
      "17748dadd25e4b8b8026fabbd272b82f",
      "1373cf6b151747e5bc1230472832bbca",
      "3f0be507531e43678593ab0cc90f0e27",
      "7c29a41b6ee6480fa7c741cd52fff221",
      "78d7b8d8d01342f6809dcea2f746c725",
      "d8041e4a6797481d822430be7e775790",
      "226798b950b9482cabf20c9ff92110f2",
      "79f3bef56c3f43e0a9e4044adda69e0b",
      "cd2e59e0b5f642d8b3fc2eccb1557cdd",
      "5252904414d547948440f22301749c7f",
      "2082f8e448d6425fbfa30985288bbfd4"
     ]
    },
    "id": "VB04HpABmjJU",
    "outputId": "632cd68b-c972-4a49-f2f8-13dcf41aacd3"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from trl import DPOConfig, DPOTrainer\n",
    "\n",
    "training_args = DPOConfig(\n",
    "    output_dir=\"./dpo_output\",\n",
    "    per_device_train_batch_size=1,\n",
    "    gradient_accumulation_steps=16,\n",
    "    num_train_epochs=1,\n",
    "    learning_rate=1e-5,\n",
    "    logging_steps=10,\n",
    "    save_steps=200,\n",
    "    eval_steps=100,\n",
    "    beta=0.1,\n",
    "    remove_unused_columns=False,\n",
    "    bf16=torch.cuda.is_available(),\n",
    "    report_to=\"none\",\n",
    ")\n",
    "\n",
    "trainer = DPOTrainer(\n",
    "    model=model,\n",
    "    ref_model=ref_model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=eval_dataset,\n",
    "    processing_class=tokenizer,\n",
    ")\n",
    "\n",
    "trainer.train()\n",
    "trainer.save_model(\"./dpo_output\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 276
    },
    "id": "fvIqBVj9FMxb",
    "outputId": "c00e3d6a-58f7-43d5-9d17-0b299d2ab603"
   },
   "outputs": [],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZBvSr3joF40M",
    "outputId": "d5d56530-f777-450d-f5fb-8585c6d68aa8"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "@torch.no_grad()\n",
    "def answer_logprob(model, tokenizer, prompt: str, answer: str) -> float:\n",
    "    prompt_ids = tokenizer(prompt, return_tensors=\"pt\", add_special_tokens=False).input_ids\n",
    "    answer_ids = tokenizer(answer, return_tensors=\"pt\", add_special_tokens=False).input_ids\n",
    "\n",
    "    input_ids = torch.cat([prompt_ids, answer_ids], dim=1).to(model.device)\n",
    "    attention_mask = torch.ones_like(input_ids)\n",
    "\n",
    "    outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "    logits = outputs.logits[:, :-1, :]\n",
    "    labels = input_ids[:, 1:]\n",
    "\n",
    "    log_probs = F.log_softmax(logits, dim=-1)\n",
    "    token_logprobs = log_probs.gather(2, labels.unsqueeze(-1)).squeeze(-1)\n",
    "\n",
    "    La = answer_ids.size(1)\n",
    "    ans_token_logprobs = token_logprobs[:, -La:]\n",
    "    return ans_token_logprobs.sum().item()\n",
    "\n",
    "def pairwise_accuracy(model, tokenizer, dataset):\n",
    "    correct = 0\n",
    "    for ex in dataset:\n",
    "        lp_c = answer_logprob(model, tokenizer, ex[\"prompt\"], ex[\"chosen\"])\n",
    "        lp_r = answer_logprob(model, tokenizer, ex[\"prompt\"], ex[\"rejected\"])\n",
    "        correct += int(lp_c > lp_r)\n",
    "    return correct / len(dataset)\n",
    "\n",
    "acc = pairwise_accuracy(model, tokenizer, eval_dataset)\n",
    "print(f\"pairwise accuracy: {acc:.1f}\")\n",
    "ref_acc = pairwise_accuracy(ref_model, tokenizer, eval_dataset)\n",
    "print(f\"ref_model pairwise accuracy: {ref_acc:.1f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7fq0RvVJM9Hc"
   },
   "outputs": [],
   "source": [
    "PVQ_questions = [\n",
    "    \"Thinking up new ideas and being creative is important to him. He likes to do things in his own original way.\",\n",
    "    \"It is important to him to be rich. He wants to have a lot of money and expensive things.\",\n",
    "    \"He thinks it is important that every person in the world be treated equally. He believes everyone should have equal opportunities in life.\",\n",
    "    \"It’s very important to him to show his abilities. He wants people to admire what he does.\",\n",
    "    \"It is important to him to live in secure surroundings. He avoids anything that might endanger his safety.\",\n",
    "    \"He thinks it is important to do lots of different things in life. He always looks for new things to try.\",\n",
    "    \"He believes that people should do what they’re told. He thinks people should follow rules at all times‚ even when no one is watching.\",\n",
    "    \"It is important to him to listen to people who are different from him. Even when he disagrees with them‚ he still wants to understand them.\",\n",
    "    \"He thinks it’s important not to ask for more than what you have. He believes that people should be satisfied with what they have.\",\n",
    "    \"He seeks every chance he can to have fun. It is important to him to do things that give him pleasure.\",\n",
    "    \"It is important to him to make his own decisions about what he does. He likes to be free to plan and to choose his activities for himself.\",\n",
    "    \"It’s very important to him to help the people around him. He wants to care for their well-being.\",\n",
    "    \"Being very successful is important to him. He likes to impress other people.\",\n",
    "    \"It is very important to him that his country be safe. He thinks the state must be on watch against threats from within and without.\",\n",
    "    \"He likes to take risks. He is always looking for adventures.\",\n",
    "    \"It is important to him to always behave properly. He wants to avoid doing anything people would say is wrong.\",\n",
    "    \"It is important to him to be in charge and tell others what to do. He wants people to do what he says.\",\n",
    "    \"It is important to him to be loyal to his friends. He wants to devote himself to people close to him.\",\n",
    "    \"He strongly believes that people should care for nature.\",\n",
    "    \"Religious belief is important to him. He tries hard to do what his religion requires.\",\n",
    "    \"It is important to him that things be organized and clean. He really does not like things to be a mess.\",\n",
    "    \"He thinks it’s important to be interested in things. He likes to be curious and to try to understand all sorts of things.\",\n",
    "    \"He believes all the world’s people should live in harmony. Promoting peace among all groups in the world is important to him.\",\n",
    "    \"He thinks it is important to be ambitious. He wants to show how capable he is.\",\n",
    "    \"He thinks it is best to do things in traditional ways. It is important to him to keep up the customs he has learned.\",\n",
    "    \"Enjoying life’s pleasures is important to him. He likes to spoil himself.\",\n",
    "    \"It is important to him to respond to the needs of others. He tries to support those he knows.\",\n",
    "    \"He believes he should always show respect to his parents and to older people. It is important to him to be obedient.\",\n",
    "    \"He wants everyone to be treated justly‚ even people he doesn't know. It is important to him to protect the weak in society.\",\n",
    "    \"He likes surprises. It is important to him to have an exciting life.\",\n",
    "    \"He tries hard to avoid getting sick. Staying healthy is very important to him.\",\n",
    "    \"Getting ahead in life is important to him. He strives to do better than others.\",\n",
    "    \"Forgiving people who have hurt him is important to him. He tries to see what is good in them and not to hold a grudge.\",\n",
    "    \"It is important to him to be independent. He likes to rely on himself.\",\n",
    "    \"Having a stable government is important to him. He is concerned that the social order be protected.\",\n",
    "    \"It is important to him to be polite to other people all the time. He tries never to disturb or irritate others.\",\n",
    "    \"He really wants to enjoy life. Having a good time is very important to him.\",\n",
    "    \"It is important to him to be humble and modest. He tries not to draw attention to himself.\",\n",
    "    \"He always wants to be the one who makes the decisions. He likes to be the leader.\",\n",
    "    \"It is important to him to adapt to nature and to fit into it. He believes that people should not change nature.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SsMKcdoEQvrd",
    "outputId": "d2320dd3-38b6-419b-c768-a341839fedb5"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "DIGITS = [\"1\", \"2\", \"3\", \"4\", \"5\", \"6\"]\n",
    "\n",
    "PROMPT_1 = \"\"\"\n",
    "        This is a self-report questionnaire that measures an individual's values based on Schwartz’s 10 basic values.\n",
    "        Please answer the following question truthfully and accurately, it is important to remember that these are subjective questions with no right or wrong answer.\n",
    "        In each case, make your choice in terms of how you feel right now on average, not what you have felt in the past or would like to feel.\n",
    "        There is 6 possible responses to each of the items in the questionnaire:\n",
    "        (1) Not at all like me; (2) Not like me; (3) A little like me; (4) Somewhat like me; (5) Like me; (6) Very much like me\n",
    "        Respond with ONLY one digit (1,2,3,4,5,6).\n",
    "        Question: {question}\n",
    "        Answer:\n",
    "        \"\"\"\n",
    "PROMPT_2 = \"\"\"\n",
    "        There is 6 possible responses to each of the items in the questionnaire:\n",
    "        (1) Not at all like me; (2) Not like me; (3) A little like me; (4) Somewhat like me; (5) Like me; (6) Very much like me\n",
    "        Respond with ONLY one digit (1,2,3,4,5,6).\n",
    "        Question: {question}\n",
    "        Answer:\n",
    "        \"\"\"\n",
    "\n",
    "def build_prompt(question: str) -> str:\n",
    "    # The short version of prompt\n",
    "    return (\n",
    "        \"Answer with ONE digit 1-6 only.\\n\"\n",
    "        \"1=Not at all like me, 6=Very much like me.\\n\"\n",
    "        f\"{question}\\nAnswer: \"\n",
    "    )\n",
    "\n",
    "@torch.no_grad()\n",
    "def pvq_score_next_token(model, tokenizer, question: str, device=None):\n",
    "    model.eval()\n",
    "    if device is None:\n",
    "        device = model.device\n",
    "\n",
    "    prompt = build_prompt(question)\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\", add_special_tokens=False).to(device)\n",
    "\n",
    "    # take the logits for the next token after the prompt\n",
    "    out = model(**inputs)\n",
    "    next_logits = out.logits[:, -1, :]\n",
    "\n",
    "    # aggregate token IDs for digits 1-6\n",
    "    digit_token_ids = []\n",
    "    for d in DIGITS:\n",
    "        ids = tokenizer(d, add_special_tokens=False).input_ids\n",
    "        if len(ids) != 1:\n",
    "            # if \"1\" is tokenized into multiple tokens\n",
    "            raise ValueError(f\"Digit '{d}' is tokenized into {ids} (len != 1). Need alternative handling.\")\n",
    "        digit_token_ids.append(ids[0])\n",
    "\n",
    "    digit_token_ids = torch.tensor(digit_token_ids, device=device)\n",
    "\n",
    "    # softmax over logits for tokens 1-6\n",
    "    digit_logits = next_logits[0, digit_token_ids]\n",
    "    probs = F.softmax(digit_logits, dim=-1)\n",
    "\n",
    "    # argmax\n",
    "    idx = torch.argmax(probs).item()\n",
    "    score = int(DIGITS[idx])\n",
    "    return score, probs.detach().cpu()\n",
    "\n",
    "def score_all_pvq(model, tokenizer, PVQ_questions):\n",
    "    scores = []\n",
    "    prob_list = []\n",
    "    for q in PVQ_questions:\n",
    "        s, p = pvq_score_next_token(model, tokenizer, q)\n",
    "        scores.append(s)\n",
    "        prob_list.append(p)\n",
    "    return scores, prob_list\n",
    "\n",
    "scores, probs = score_all_pvq(model, tokenizer, PVQ_questions)\n",
    "\n",
    "for i, (q, s) in enumerate(zip(PVQ_questions, scores), 1):\n",
    "    print(f\"{i:02d}. {s} | {q}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ve09le8nS5tV",
    "outputId": "40b7a702-fd32-46c2-cd10-e1adca6aba26"
   },
   "outputs": [],
   "source": [
    "import os, json\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "DIGITS = [\"1\", \"2\", \"3\", \"4\", \"5\", \"6\"]\n",
    "\n",
    "PROMPT_1 = \"\"\"\n",
    "        This is a self-report questionnaire that measures an individual's values based on Schwartz’s 10 basic values.\n",
    "        Please answer the following question truthfully and accurately, it is important to remember that these are subjective questions with no right or wrong answer.\n",
    "        In each case, make your choice in terms of how you feel right now on average, not what you have felt in the past or would like to feel.\n",
    "        There is 6 possible responses to each of the items in the questionnaire:\n",
    "        (1) Not at all like me; (2) Not like me; (3) A little like me; (4) Somewhat like me; (5) Like me; (6) Very much like me\n",
    "        Respond with ONLY one digit (1,2,3,4,5,6).\n",
    "        Question: {question}\n",
    "        Answer:\n",
    "        \"\"\"\n",
    "PROMPT_2 = \"\"\"\n",
    "        There is 6 possible responses to each of the items in the questionnaire:\n",
    "        (1) Not at all like me; (2) Not like me; (3) A little like me; (4) Somewhat like me; (5) Like me; (6) Very much like me\n",
    "        Respond with ONLY one digit (1,2,3,4,5,6).\n",
    "        Question: {question}\n",
    "        Answer:\n",
    "        \"\"\"\n",
    "\n",
    "def build_prompt(question: str) -> str:\n",
    "    # The shorter version of prompt\n",
    "    return (\n",
    "        \"Answer with ONE digit 1-6 only.\\n\"\n",
    "        \"1=Not at all like me, 6=Very much like me.\\n\"\n",
    "        f\"{question}\\nAnswer: \"\n",
    "    )\n",
    "\n",
    "def get_single_token_id(tokenizer, s: str):\n",
    "    ids = tokenizer(s, add_special_tokens=False).input_ids\n",
    "    return ids[0] if len(ids) == 1 else None\n",
    "\n",
    "def get_digit_token_ids(tokenizer):\n",
    "    digit_token_ids = []\n",
    "    for d in DIGITS:\n",
    "        tid = get_single_token_id(tokenizer, d)\n",
    "        if tid is None:\n",
    "            tid = get_single_token_id(tokenizer, \" \" + d)\n",
    "        if tid is None:\n",
    "            raise ValueError(\n",
    "                f\"Digit '{d}' could not be represented as a single token by this tokenizer. \"\n",
    "                \"Try changing prompt formatting or implement multi-token scoring.\"\n",
    "            )\n",
    "        digit_token_ids.append(tid)\n",
    "    return torch.tensor(digit_token_ids, device=\"cpu\")\n",
    "\n",
    "@torch.no_grad()\n",
    "def pvq_scores_for_model(model, tokenizer, PVQ_questions):\n",
    "    model.eval()\n",
    "    device = model.device\n",
    "\n",
    "    digit_token_ids = get_digit_token_ids(tokenizer).to(device)  # (6,)\n",
    "\n",
    "    scores = {}\n",
    "    for i, q in enumerate(PVQ_questions, start=1):\n",
    "        prompt = build_prompt(q)\n",
    "        inputs = tokenizer(prompt, return_tensors=\"pt\", add_special_tokens=False).to(device)\n",
    "\n",
    "        out = model(**inputs)\n",
    "        next_logits = out.logits[:, -1, :]              # (1, vocab)\n",
    "        digit_logits = next_logits[0, digit_token_ids]  # (6,)\n",
    "        probs = F.softmax(digit_logits, dim=-1)         # (6,)\n",
    "\n",
    "        idx = torch.argmax(probs).item()\n",
    "        score = int(DIGITS[idx])\n",
    "\n",
    "        scores[str(i)] = score\n",
    "\n",
    "    return scores\n",
    "\n",
    "out_dir = \"/content/drive/MyDrive/datasets\"\n",
    "os.makedirs(out_dir, exist_ok=True)\n",
    "out_path = os.path.join(out_dir, \"PVQ_result.json\")\n",
    "\n",
    "if os.path.exists(out_path):\n",
    "    with open(out_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        result = json.load(f)\n",
    "else:\n",
    "    result = {}\n",
    "\n",
    "result[USER] = {\n",
    "    \"model\": pvq_scores_for_model(model, tokenizer, PVQ_questions),\n",
    "    \"ref_model\": pvq_scores_for_model(ref_model, tokenizer, PVQ_questions),\n",
    "}\n",
    "\n",
    "with open(out_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(result, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(\"Saved to:\", out_path)\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
